{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor x in surreal.load():\\n    print(x)\\n    break\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import surreal, config\n",
    "import functools, operator, copy\n",
    "import tensorflow.contrib.slim as slim\n",
    "from nets.resnet_v2 import resnet_v2_101\n",
    "from nets.mobilenet import mobilenet_v2\n",
    "from tensor_info import INPUT_TENSOR_INFO, OUTPUT_TENSOR_INFO\n",
    "tf.reset_default_graph()\n",
    "'''\n",
    "for x in surreal.load():\n",
    "    print(x)\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = tuple(t['type'] for t in INPUT_TENSOR_INFO)\n",
    "input_tensors = tf.data.Dataset.from_generator(surreal.load, types) \\\n",
    "                               .batch(config.BATCH_SIZE) \\\n",
    "                               .prefetch(config.PREFETCH_SIZE) \\\n",
    "                               .make_one_shot_iterator() \\\n",
    "                               .get_next()\n",
    "tensors = {}\n",
    "for tensor, info in zip(input_tensors, INPUT_TENSOR_INFO):\n",
    "    tensor.set_shape(info['shape'])\n",
    "    tensors[info['name']] = tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config.STRIDE = 16\n",
    "\n",
    "MD_H = int(config.TAR_H/config.STRIDE)\n",
    "MD_W = int(config.TAR_W/config.STRIDE)\n",
    "\n",
    "DEPTH = [ti['shape'][-1] for ti in OUTPUT_TENSOR_INFO]\n",
    "RESULT_SHAPE = (config.BATCH_SIZE, MD_H, MD_W, sum(DEPTH))\n",
    "RESULT_SIZE = functools.reduce(operator.mul, RESULT_SHAPE[1:])\n",
    "OUTPUT_SHAPE = (config.BATCH_SIZE, config.TAR_H, config.TAR_W, sum(DEPTH))\n",
    "OUTPUT_SIZE = functools.reduce(operator.mul, OUTPUT_SHAPE[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear(indices):\n",
    "    oy = tf.clip_by_value(indices[1], 0, MD_H-1)\n",
    "    ox = tf.clip_by_value(indices[2], 0, MD_W-1)\n",
    "    iy = [tf.floor(oy), tf.ceil(oy)]\n",
    "    ix = [tf.floor(ox), tf.ceil(ox)]\n",
    "    idx_p = []\n",
    "    for y_i in range(2):\n",
    "        for x_i in range(2):\n",
    "            indices[1] = iy[y_i]\n",
    "            indices[2] = ix[x_i]\n",
    "            idx = tf.cast(tf.stack(indices, axis=-1), tf.int32)\n",
    "            p = (1 - tf.abs(iy[y_i] - oy)) * (1 - tf.abs(ix[x_i] - ox))\n",
    "            idx_p.append((idx, p))\n",
    "    return idx_p\n",
    "\n",
    "def gather_bilinear(params, indices):\n",
    "    idx_p = bilinear(indices)\n",
    "    res = []\n",
    "    for idx, p in idx_p:\n",
    "        r = tf.gather_nd(params, idx)\n",
    "        res.append(r * p)\n",
    "    return tf.add_n(res)\n",
    "\n",
    "def scatter_bilinear(params, indices, shape):\n",
    "    idx_p = bilinear(indices)\n",
    "    res = []\n",
    "    for idx, p in idx_p:\n",
    "        r = tf.scatter_nd(idx, params, shape)\n",
    "        if len(r.shape) > len(p.shape):\n",
    "            p = tf.expand_dims(p, axis=-1)\n",
    "        res.append(r * p)\n",
    "    return tf.add_n(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCell(tf.contrib.rnn.RNNCell):\n",
    "    def __init__(self, is_training):\n",
    "        super().__init__(self)\n",
    "        self.is_training = is_training\n",
    "        \n",
    "    def resize(self, tensor):\n",
    "        return tf.image.resize_images(\n",
    "            tensor,\n",
    "            (config.TAR_H, config.TAR_W),\n",
    "            method=tf.image.ResizeMethod.BICUBIC,\n",
    "            align_corners=True)\n",
    "    \n",
    "    def __call__(self, frame_tensor, state):\n",
    "        model_output, _ = resnet_v2_101(frame_tensor, output_stride=config.STRIDE)\n",
    "        # state = tf.reshape(state, RESULT_SHAPE)\n",
    "        \n",
    "        # model_output = tf.concat([model_output, state], axis=-1)\n",
    "        # _, so_x_prev, so_y_prev, mo_x_prev, mo_y_prev = tf.split(state, DEPTH, axis=-1)\n",
    "        \n",
    "        hm_pred = slim.conv2d(model_output, config.NUM_KP, [1, 1])\n",
    "        so_x_pred = slim.conv2d(model_output, config.NUM_KP, [1, 1]) # + so_x_prev\n",
    "        so_y_pred = slim.conv2d(model_output, config.NUM_KP, [1, 1]) # + so_y_prev\n",
    "        mo_x_pred = slim.conv2d(model_output, config.NUM_EDGE, [1, 1]) # + mo_x_prev\n",
    "        mo_y_pred = slim.conv2d(model_output, config.NUM_EDGE, [1, 1]) # + mo_y_prev\n",
    "        \n",
    "        '''\n",
    "        mv_x_pred = tf.squeeze(slim.conv2d(model_output, 1, [1, 1]), axis=[-1])\n",
    "        mv_y_pred = tf.squeeze(slim.conv2d(model_output, 1, [1, 1]), axis=[-1])\n",
    "        \n",
    "        b, y, x = np.mgrid[:config.BATCH_SIZE, :MD_H, :MD_W]\n",
    "        mv_p = [b, y + mv_y_pred, x + mv_x_pred]\n",
    "        \n",
    "        hm_expect = scatter_bilinear(hm_pred, mv_p, hm_pred.shape)\n",
    "        so_x_expect = scatter_bilinear(so_x_pred, mv_p, so_x_pred.shape)\n",
    "        so_y_expect = scatter_bilinear(so_y_pred, mv_p, so_y_pred.shape)\n",
    "        \n",
    "        b, y, x, i = np.mgrid[:config.BATCH_SIZE, :MD_H, :MD_W, :config.NUM_EDGE]\n",
    "        for _ in range(config.NUM_RECURRENT):\n",
    "            mo_p = [b, y+mo_y_pred, x+mo_x_pred, i]\n",
    "            mo_x_pred = gather_bilinear(so_x_pred, mo_p) + mo_x_pred\n",
    "            mo_y_pred = gather_bilinear(so_y_pred, mo_p) + mo_y_pred\n",
    "        \n",
    "        mo_p = [b, y+mo_y_pred, x+mo_x_pred]\n",
    "        mo_x_expect_in_cp = gather_bilinear(mv_x_pred, mo_p) + \\\n",
    "                            mo_x_pred - tf.expand_dims(mv_x_pred, axis=-1)\n",
    "        mo_y_expect_in_cp = gather_bilinear(mv_y_pred, mo_p) + \\\n",
    "                            mo_y_pred - tf.expand_dims(mv_y_pred, axis=-1)\n",
    "        mo_x_expect = scatter_bilinear(mo_x_expect_in_cp, mv_p, mo_x_pred.shape)\n",
    "        mo_y_expect = scatter_bilinear(mo_y_expect_in_cp, mv_p, mo_y_pred.shape)\n",
    "        \n",
    "        next_state = tf.concat([hm_expect, so_x_expect, so_y_expect, mo_x_expect, mo_y_expect], axis=-1)\n",
    "        next_state = tf.reshape(next_state, [config.BATCH_SIZE, RESULT_SIZE])\n",
    "        '''\n",
    "        output = tf.concat([hm_pred, \\\n",
    "                            so_x_pred*config.STRIDE, so_y_pred*config.STRIDE, \\\n",
    "                            mo_x_pred*config.STRIDE, mo_y_pred*config.STRIDE], axis=-1)\n",
    "        output = self.resize(output)\n",
    "        output = tf.reshape(output, [config.BATCH_SIZE, OUTPUT_SIZE])\n",
    "        \n",
    "        return output, state #next_state\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return RESULT_SIZE\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return OUTPUT_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_cell = TestCell(is_training=True)\n",
    "#with tf.contrib.slim.arg_scope(mobilenet_v2.training_scope(is_training=True)):\n",
    "pred_sum, _ = tf.nn.dynamic_rnn(test_cell, tensors['image'], sequence_length=tensors['seq_len'], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SHAPE = (config.BATCH_SIZE, config.MAX_FRAME_SIZE, config.TAR_H, config.TAR_W, sum(DEPTH))\n",
    "pred_sum = tf.reshape(pred_sum, TOTAL_SHAPE)\n",
    "hm_out, so_x_out, so_y_out, mo_x_out, mo_y_out = tf.split(pred_sum, DEPTH, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_sig = tf.sigmoid(hm_out)\n",
    "hm_loss = - tf.reduce_mean(tensors['hm'] * tf.log(hm_sig + 1e-9) + (1 - tensors['hm']) * tf.log(1 - hm_sig + 1e-9))\n",
    "so_loss = tf.abs(tensors['so_x'] - so_x_out) / config.RADIUS + tf.abs(tensors['so_y'] - so_y_out) / config.RADIUS\n",
    "mo_loss = tf.abs(tensors['mo_x'] - mo_x_out) / config.RADIUS + tf.abs(tensors['mo_y'] - mo_y_out) / config.RADIUS\n",
    "\n",
    "disc_only = tf.cast(tensors['hm'], tf.float32)\n",
    "disc_size = tf.reduce_sum(disc_only, axis=[2, 3]) + 1e-9\n",
    "so_loss = tf.reduce_mean(tf.reduce_sum(so_loss * disc_only, axis=[2, 3]) / disc_size)\n",
    "\n",
    "disc_only = tf.cast(tf.gather(tensors['hm'], config.EDGES[:, 0], axis=-1), tf.float32)\n",
    "disc_size = tf.reduce_sum(disc_only, axis=[2, 3]) + 1e-9\n",
    "mo_loss = tf.reduce_mean(tf.reduce_sum(mo_loss * disc_only, axis=[2, 3]) / disc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = hm_loss * 4.0 + so_loss * 1.0 + mo_loss * 0.5\n",
    "#total_loss = so_loss * 1.0 + mo_loss * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'losses/total_loss:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar('losses/hm_loss', hm_loss)\n",
    "tf.summary.scalar('losses/so_loss', so_loss)\n",
    "tf.summary.scalar('losses/mo_loss', mo_loss)\n",
    "tf.summary.scalar('losses/total_loss', total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.summary.scalar('val/hm_sum', tf.reduce_sum(hm_out))\n",
    "tf.summary.scalar('val/hm_min', tf.reduce_min(hm_out))\n",
    "tf.summary.scalar('val/hm_max', tf.reduce_max(hm_out))\n",
    "tf.summary.scalar('val/so_min', tf.reduce_min(so_x_out))\n",
    "tf.summary.scalar('val/so_max', tf.reduce_max(so_x_out))\n",
    "tf.summary.scalar('val/so_sum', tf.reduce_sum(tf.abs(so_x_out)) + tf.reduce_sum(tf.abs(so_y_out)))\n",
    "tf.summary.scalar('val/mo_sum', tf.reduce_sum(tf.abs(mo_x_out)) + tf.reduce_sum(tf.abs(mo_y_out)))\n",
    "tf.summary.scalar('val/hm_true_sum', tf.reduce_sum(tensors['hm']))\n",
    "tf.summary.scalar('val/so_true_sum', tf.reduce_sum(tf.abs(tensors['so_x'])) + tf.reduce_sum(tf.abs(tensors['so_y'])))\n",
    "tf.summary.scalar('val/mo_true_sum', tf.reduce_sum(tf.abs(tensors['mo_x'])) + tf.reduce_sum(tf.abs(tensors['mo_y'])))\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "\n",
    "checkpoint_path = 'mbnet/mobilenet_v2_1.0_224.ckpt'\n",
    "variables = slim.get_model_variables()\n",
    "restore_map = {}\n",
    "for v in variables:\n",
    "    if not v.name.startswith('rnn/MobilenetV2'):\n",
    "        continue\n",
    "    org_name = v.name[4:].split(':')[0]\n",
    "    restore_map[org_name] = v\n",
    "    print(org_name, ':', v.name)\n",
    "init_assign_op, init_feed_dict = slim.assign_from_checkpoint(checkpoint_path, restore_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, shutil\n",
    "#log_dir = 'logs/log_' + str(time.time())[-5:]\n",
    "log_dir = 'logs/log_test2'\n",
    "shutil.rmtree(log_dir)\n",
    "os.mkdir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Saving checkpoint to path /home/ubuntu/personlab/logs/log_test2/model.ckpt\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:Recording summary at step 0.\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, The node 'train_op/CheckNumerics' has inputs from different frames. The input 'add_8' is in frame ''. The input 'rnn/while/resnet_v2_101/postnorm/AssignMovingAvg_1' is in frame 'rnn/while/while_context'.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "The node 'train_op/CheckNumerics' has inputs from different frames. The input 'add_8' is in frame ''. The input 'rnn/while/resnet_v2_101/postnorm/AssignMovingAvg_1' is in frame 'rnn/while/while_context'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: The node 'train_op/CheckNumerics' has inputs from different frames. The input 'add_8' is in frame ''. The input 'rnn/while/resnet_v2_101/postnorm/AssignMovingAvg_1' is in frame 'rnn/while/while_context'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-e97a3a46e83f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0minit_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInitAssignFn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                \u001b[0mlog_every_n_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                                \u001b[0msave_summaries_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m                               )\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_op, logdir, train_step_fn, train_step_kwargs, log_every_n_steps, graph, master, is_chief, global_step, number_of_steps, init_op, init_feed_dict, local_init_op, init_fn, ready_op, summary_op, save_summaries_secs, summary_writer, startup_delay_steps, saver, save_interval_secs, sync_optimizer, session_config, session_wrapper, trace_every_n_steps, ignore_live_threads)\u001b[0m\n\u001b[1;32m    767\u001b[0m           \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             total_loss, should_stop = train_step_fn(\n\u001b[0;32m--> 769\u001b[0;31m                 sess, train_op, global_step, train_step_kwargs)\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m               \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stopping Training.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/contrib/slim/python/slim/learning.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(sess, train_op, global_step, train_step_kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m   total_loss, np_global_step = sess.run([train_op, global_step],\n\u001b[1;32m    486\u001b[0m                                         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrace_run_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                                         run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    488\u001b[0m   \u001b[0mtime_elapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: The node 'train_op/CheckNumerics' has inputs from different frames. The input 'add_8' is in frame ''. The input 'rnn/while/resnet_v2_101/postnorm/AssignMovingAvg_1' is in frame 'rnn/while/while_context'."
     ]
    }
   ],
   "source": [
    "def InitAssignFn(sess):\n",
    "    sess.run(init_assign_op, init_feed_dict)\n",
    "tf.contrib.slim.learning.train(train_op,\n",
    "                               '/home/ubuntu/personlab/'+log_dir,\n",
    "                               init_fn=InitAssignFn,\n",
    "                               log_every_n_steps=100,\n",
    "                               save_summaries_secs=30,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
